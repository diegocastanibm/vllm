INFO 07-01 03:50:35 [default_loader.py:272] Loading weights took 0.54 seconds
INFO 07-01 03:50:35 [gpu_model_runner.py:1758] Model loading took 2.3185 GiB and 1.275900 seconds
DEBUG 07-01 03:50:35 [decorators.py:204] Start compiling function <code object forward at 0xd57dcd0, file "/app/vllm/vllm/model_executor/models/llama.py", line 368>
DEBUG 07-01 03:50:38 [backends.py:461] Traced files (to be considered for compilation cache):
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/attention/layer.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/distributed/communication_op.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/distributed/parallel_state.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/custom_op.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/activation.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/layernorm.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/linear.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/rotary_embedding.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/utils.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/layers/vocab_parallel_embedding.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/model_executor/models/llama.py
DEBUG 07-01 03:50:38 [backends.py:461] /app/vllm/vllm/platforms/interface.py
DEBUG 07-01 03:50:38 [backends.py:461] /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py
DEBUG 07-01 03:50:38 [backends.py:461] /usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py
DEBUG 07-01 03:50:38 [backends.py:461] /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py
INFO 07-01 03:50:39 [backends.py:508] Using cache directory: /root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/backbone for vLLM's torch.compile
INFO 07-01 03:50:39 [backends.py:519] Dynamo bytecode transform time: 3.56 s
DEBUG 07-01 03:50:39 [backends.py:123] Directly load the 0-th graph for shape None from inductor via handle ('ffeco5ncb3f2alfnnh6zzmdytcgdhb5tgyenzu76nuvnlcfx6mmf', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/jq/cjqrhjyzuqaa33r227zhiw2fk2trgprfbqh7bmkljqrrijt7qnou.py')
DEBUG 07-01 03:50:39 [backends.py:123] Directly load the 1-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:39 [backends.py:123] Directly load the 2-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:39 [backends.py:123] Directly load the 3-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:40 [backends.py:123] Directly load the 4-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:40 [backends.py:123] Directly load the 5-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:40 [backends.py:123] Directly load the 6-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:40 [backends.py:123] Directly load the 7-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:40 [backends.py:123] Directly load the 8-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 9-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 10-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 11-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 12-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 13-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:41 [backends.py:123] Directly load the 14-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:42 [backends.py:123] Directly load the 15-th graph for shape None from inductor via handle ('frtunqyu7ungwnu3twyonrlvawuf2bsigdlliq67jz32xs6bnn5w', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/5t/c5tmy3q734idhefl3l7x7wnfz57ed6ln3lxi6gn5er533gwvklso.py')
DEBUG 07-01 03:50:42 [backends.py:123] Directly load the 16-th graph for shape None from inductor via handle ('fjsat3zgzmaayosbucjmszdzf2szucjtjdxitj4xvcteqvxt34bc', '/root/.cache/vllm/torch_compile_cache/2d4e0c54fd/rank_0_0/inductor_cache/4e/c4en5ucqzyeck3k5ss3b6mwre2dxe6n6ne62uzog3mbachn72lru.py')
INFO 07-01 03:50:42 [backends.py:155] Directly load the compiled graph(s) for shape None from the cache, took 2.786 s
INFO 07-01 03:50:42 [monitor.py:34] torch.compile takes 3.56 s in total
DEBUG 07-01 03:50:42 [utils.py:485] Waiting for 1 local, 0 remote core engine proc(s) to start.
DEBUG 07-01 03:50:43 [gpu_worker.py:226] Initial free memory: 43.89 GiB, free memory: 41.43 GiB, requested GPU memory: 39.88 GiB
DEBUG 07-01 03:50:43 [gpu_worker.py:231] Memory profiling takes 7.47 seconds. Total non KV cache memory: 2.85GiB; torch peak memory increase: 0.45GiB; non-torch forward increase memory: 0.08GiB; weights memory: 2.32GiB.
INFO 07-01 03:50:43 [gpu_worker.py:232] Available KV cache memory: 37.03 GiB
INFO 07-01 03:50:43 [kv_cache_utils.py:716] GPU KV cache size: 1,213,376 tokens
INFO 07-01 03:50:43 [kv_cache_utils.py:720] Maximum concurrency for 131,072 tokens per request: 9.26x
WARNING 07-01 03:50:43 [utils.py:101] Unable to detect current VLLM co
